{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Movie Recommendation Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source:  https://www.codementor.io/@jadianes/building-a-recommender-with-apache-spark-python-example-app-part1-du1083qbw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SpartContext configured for local mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small: 100,000 ratings and 2,488 tag applications applied to 8,570 movies by 706 users. Last updated 4/2015.  \n",
    "Full: 21,000,000 ratings and 470,000 tag applications applied to 27,000 movies by 230,000 users. Last updated 4/2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datasets_path = os.path.join('..', 'datasets')\n",
    "\n",
    "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
    "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "small_f = urllib.request.urlretrieve (small_dataset_url, small_dataset_path)\n",
    "complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "\n",
    "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Parsing datasests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "\n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data.take(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Toy Story (1995)'),\n",
       " ('2', 'Jumanji (1995)'),\n",
       " ('3', 'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
    "\n",
    "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
    "    \n",
    "small_movies_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting ALS parameters using the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.908078105265682\n",
      "For rank 8 the RMSE is 0.916462973348527\n",
      "For rank 12 the RMSE is 0.917665030756129\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print ('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print ('The best model was trained with rank %s' % best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((372, 1084), 3.42419871162954),\n",
       " ((4, 1084), 3.866749726695713),\n",
       " ((402, 1084), 3.4099577968422152)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 457), (5.0, 4.381060760461434)),\n",
       " ((1, 1025), (5.0, 4.705295366590298)),\n",
       " ((1, 1089), (5.0, 4.979982471805129))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.9113780946334407\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the complete dataset to build the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33832162 recommendations in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "# Load the complete dataset file\n",
    "complete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\n",
    "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
    "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "    \n",
    "print (\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
    "\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.8257054095972955\n"
     ]
    }
   ],
   "source": [
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86537 movies in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "    \n",
    "print (\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of ratings per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new user ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 1721, 4), (0, 1580, 4), (0, 3593, 1), (0, 4896, 5), (0, 209061, 5), (0, 109487, 4), (0, 588, 3), (0, 586, 3), (0, 74530, 5), (0, 76056, 2)]\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "# new_user_ratings = [\n",
    "#      (0,260,4), # Star Wars (1977)\n",
    "#      (0,1,3), # Toy Story (1995)\n",
    "#      (0,16,3), # Casino (1995)\n",
    "#      (0,25,4), # Leaving Las Vegas (1995)\n",
    "#      (0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
    "#      (0,335,1), # Flintstones, The (1994)\n",
    "#      (0,379,1), # Timecop (1994)\n",
    "#      (0,296,3), # Pulp Fiction (1994)\n",
    "#      (0,858,5) , # Godfather, The (1972)\n",
    "#      (0,50,4) # Usual Suspects, The (1995)\n",
    "#     ]\n",
    "\n",
    "# Scenario 1 \n",
    "# new_user_ratings = [\n",
    "#      (0,260,5), # Star Wars (1977)\n",
    "#      (0,1036,3), # Die Hard (1988)\n",
    "#      (0,1040,3), # Secret Agent, The (1996)\n",
    "#      (0,1197,2), # Princess Bride, The (1987)\n",
    "#      (0,1221,3), # Godfather: Part II, The (1974)\n",
    "#      (0,1240,4), # Terminator, The (1984)\n",
    "#      (0,1293,5), # Gandhi (1982)\n",
    "#      (0,1307,3), # When Harry Met Sally... (1989)\n",
    "#      (0,1371,5) , # Star Trek: The Motion Picture (1979)\n",
    "#      (0,1499,4) # Anaconda (1997)\n",
    "#     ]\n",
    "\n",
    "# Scenario 2\n",
    "new_user_ratings = [\n",
    "     (0,1721,4), # Titanic (1997)\n",
    "     (0,1580,4), # Men in Black (a.k.a. MIB) (1997)\n",
    "     (0,3593,1), # Battlefield Earth (2000)\n",
    "     (0,4896,5), # Harry Potter and the Sorcerer's Stone\n",
    "     (0,209061,5), # Sherlock Holmes: The Last Vampyre (1993)\n",
    "     (0,109487,4), # Interstellar (2014)\n",
    "     (0,588,3), # Aladdin (1992)\n",
    "     (0,586,3), # Home Alone (1990)\n",
    "     (0,74530,5) , # Percy Jackson & the Olympians\n",
    "     (0,76056,2) # New York (2009)\n",
    "    ]\n",
    "\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: %s' % new_user_ratings_RDD.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 270.627 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print (\"New model trained in %s seconds\" % round(tt,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(257805, ((3.2340933988270777, 'Best Sellers (2021)'), 32)),\n",
       " (154530, ((0.2071116570099416, 'Recto / verso'), 2)),\n",
       " (71910, ((3.020696128450151, '\"Tournament'), 268))]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out movies with less than 25 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies (with more than 25 reviews):\n",
      "('Pollyanna (2003)', 4.805593947106426, 33)\n",
      "('The Bible (2013)', 4.7670745731646385, 31)\n",
      "('Shaadi Mein Zaroor Aana (2017)', 4.700950824647783, 26)\n",
      "('Love is God (2003)', 4.618226139505859, 27)\n",
      "('Den radio (2001)', 4.607191996406179, 38)\n",
      "('Rent: Filmed Live on Broadway (2008)', 4.602257329767031, 41)\n",
      "('Border (1997)', 4.595495226646453, 38)\n",
      "('The Butterfly Circus (2009)', 4.573118339696792, 44)\n",
      "('North & South (2004)', 4.543987827272972, 485)\n",
      "('Us Again (2021)', 4.530712454637214, 37)\n",
      "('Iron Jawed Angels (2004)', 4.521868949143901, 50)\n",
      "('I Can Only Imagine (2018)', 4.508390072967761, 81)\n",
      "('Mower Minions (2016)', 4.508144195710038, 42)\n",
      "('Trevor Noah: Son of Patricia (2018)', 4.506821801933262, 69)\n",
      "('Drishyam 2 (2021)', 4.5052843366990825, 34)\n"
     ]
    }
   ],
   "source": [
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, top_movies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out movies with less than 100 ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies (with more than 100 reviews):\n",
      "('North & South (2004)', 4.543987827272972, 485)\n",
      "('Pride and Prejudice (1995)', 4.484005894475069, 3229)\n",
      "('War Room (2015)', 4.458380950141752, 108)\n",
      "('The Biggest Little Farm (2018)', 4.451077478196729, 121)\n",
      "('Gifted Hands: The Ben Carson Story (2009)', 4.443992178835147, 153)\n",
      "('Hamilton (2020)', 4.427148150887166, 2094)\n",
      "('Sense & Sensibility (2008)', 4.408884334165066, 101)\n",
      "('Hidden Figures (2016)', 4.40304559228319, 5878)\n",
      "('Harry Potter and the Deathly Hallows: Part 2 (2011)', 4.361168749350742, 20837)\n",
      "('The Hundred-Foot Journey (2014)', 4.352469671627779, 959)\n",
      "('Spider-Man: Across the Spider-Verse (2023)', 4.344597143128013, 528)\n",
      "('Piper (2016)', 4.3297060915042085, 2007)\n",
      "('Fireproof (2008)', 4.327696953171022, 264)\n",
      "('Harry Potter and the Deathly Hallows: Part 1 (2010)', 4.325495693359052, 21781)\n",
      "('\"Sound of Music', 4.32045234753871, 19092)\n"
     ]
    }
   ],
   "source": [
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=100).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 100 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, top_movies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting individual ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=0, product=206085, rating=2.4763291156674185)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\n",
    "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "individual_movie_rating_RDD.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User 1 - Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP recommended movies (with more than 25 reviews):\n",
    "('Detective Conan: The Last Wizard of the Century (1999)', 4.633993246282561, 34)\n",
    "('Doctor Who: The Waters of Mars (2009)', 4.458570909746342, 44)\n",
    "('Pandora (2016)', 4.4247919138691145, 46)\n",
    "('Detective Conan: The Fourteenth Target (1998)', 4.3731528473059065, 32)\n",
    "('Doctor Who: Voyage of the Damned (2007)', 4.356283708898584, 29)\n",
    "('Louis C.K.: Sorry (2021)', 4.338982219498405, 39)\n",
    "(\"Sharpe's Sword (1995)\", 4.3299668217185605, 27)\n",
    "('One Piece Film: GOLD (2016)', 4.326239213581131, 42)\n",
    "('Avengers: Infinity War - Part II (2019)', 4.314938214509443, 12845)\n",
    "('Avengers: Infinity War - Part I (2018)', 4.313439277912256, 16164)\n",
    "(\"KonoSuba: God's Blessing on this Wonderful World! Legend of Crimson (2019)\", 4.3104578938773095, 51)\n",
    "('What a Beautiful Day (2011)', 4.285629586377734, 31)\n",
    "('Like Minds (2006)', 4.274245695172404, 35)\n",
    "('Pope Joan (Die Päpstin) (2009)', 4.267095285167905, 39)\n",
    "('Indictment: The McMartin Trial (1995)', 4.266934955634852, 29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User 1 - Scenario 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP recommended movies (with more than 100 reviews):\n",
    "('Avengers: Infinity War - Part II (2019)', 4.314938214509443, 12845)\n",
    "('Avengers: Infinity War - Part I (2018)', 4.313439277912256, 16164)\n",
    "('\"Avengers', 4.265181848406174, 27495)\n",
    "('Iron Man (2008)', 4.259699045249739, 38308)\n",
    "('The Lost Room (2006)', 4.2458191200893545, 445)\n",
    "('The Matrix Revisited (2001)', 4.243257013533455, 160)\n",
    "('\"Dark Knight', 4.241962245395641, 65349)\n",
    "('Death Note: R2 - L o Tsugu Mono (2008)', 4.238266855082774, 104)\n",
    "('\"Dark Knight Rises', 4.230359727598167, 31704)\n",
    "('Gladiator (2000)', 4.229830562371291, 60749)\n",
    "('\"Rock', 4.227283772666121, 40412)\n",
    "('Gladiator (1992)', 4.212721830277712, 3875)\n",
    "('Band of Brothers (2001)', 4.211012921375094, 2835)\n",
    "('Law Abiding Citizen (2009)', 4.200478496684738, 4192)\n",
    "('Firefly (2002)', 4.195350066534203, 895)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User 2 - Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP recommended movies (with more than 25 reviews):\n",
    "('Pollyanna (2003)', 4.805593947106426, 33)\n",
    "('The Bible (2013)', 4.7670745731646385, 31)\n",
    "('Shaadi Mein Zaroor Aana (2017)', 4.700950824647783, 26)\n",
    "('Love is God (2003)', 4.618226139505859, 27)\n",
    "('Den radio (2001)', 4.607191996406179, 38)\n",
    "('Rent: Filmed Live on Broadway (2008)', 4.602257329767031, 41)\n",
    "('Border (1997)', 4.595495226646453, 38)\n",
    "('The Butterfly Circus (2009)', 4.573118339696792, 44)\n",
    "('North & South (2004)', 4.543987827272972, 485)\n",
    "('Us Again (2021)', 4.530712454637214, 37)\n",
    "('Iron Jawed Angels (2004)', 4.521868949143901, 50)\n",
    "('I Can Only Imagine (2018)', 4.508390072967761, 81)\n",
    "('Mower Minions (2016)', 4.508144195710038, 42)\n",
    "('Trevor Noah: Son of Patricia (2018)', 4.506821801933262, 69)\n",
    "('Drishyam 2 (2021)', 4.5052843366990825, 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User 2 - Scenario 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP recommended movies (with more than 100 reviews):\n",
    "('North & South (2004)', 4.543987827272972, 485)\n",
    "('Pride and Prejudice (1995)', 4.484005894475069, 3229)\n",
    "('War Room (2015)', 4.458380950141752, 108)\n",
    "('The Biggest Little Farm (2018)', 4.451077478196729, 121)\n",
    "('Gifted Hands: The Ben Carson Story (2009)', 4.443992178835147, 153)\n",
    "('Hamilton (2020)', 4.427148150887166, 2094)\n",
    "('Sense & Sensibility (2008)', 4.408884334165066, 101)\n",
    "('Hidden Figures (2016)', 4.40304559228319, 5878)\n",
    "('Harry Potter and the Deathly Hallows: Part 2 (2011)', 4.361168749350742, 20837)\n",
    "('The Hundred-Foot Journey (2014)', 4.352469671627779, 959)\n",
    "('Spider-Man: Across the Spider-Verse (2023)', 4.344597143128013, 528)\n",
    "('Piper (2016)', 4.3297060915042085, 2007)\n",
    "('Fireproof (2008)', 4.327696953171022, 264)\n",
    "('Harry Potter and the Deathly Hallows: Part 1 (2010)', 4.325495693359052, 21781)\n",
    "('\"Sound of Music', 4.32045234753871, 19092)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
