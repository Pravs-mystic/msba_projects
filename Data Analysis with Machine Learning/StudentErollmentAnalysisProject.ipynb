{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7978f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,mean_squared_error, r2_score\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv(\"sudata.csv\")\n",
    "\n",
    "# Convert column names to camelCase\n",
    "colNames = [col.replace(\" \", \"\").replace(\"_\", \"\").replace(\"-\", \"\").replace(\"(\", \"\").replace(\")\", \"\") for col in df.columns]\n",
    "colNames = [col[0].lower() + col[1:] if col else \"\" for col in colNames]\n",
    "colNames = [colNames[i] if i == 0 else colNames[i][0].upper() + colNames[i][1:] for i in range(len(colNames))]\n",
    "\n",
    "# Assign the new column names to the DataFrame\n",
    "df.columns = colNames\n",
    "\n",
    "print(df.columns.to_numpy())\n",
    "\n",
    "df['ApplicationsRegisteredinCollege'] = df['ApplicationsRegisteredinColleague']\n",
    "\n",
    "continuous_vars = ['RecordCreatedDate', 'ApplicationCreatedDate', 'DecisionsReleasedDate', 'TestsGMATTotal','GPAConverted', 'Age', 'Intendtoapplyforfinancialaid', 'ApplicationsRegisteredinCollege', 'ApplicationsScholarshipTierAdmit']\n",
    "categorical_vars = ['ApplicationStatus', 'ApplicationProgram', 'ApplicationStartTerm', 'DecisionReason', 'Country', 'VisaType','Race', 'Sex']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# HANDLING MISSING VALUES\n",
    "\n",
    "print('HANDLING MISSING VALUES\\n')\n",
    "# Finding number of missing values in each column\n",
    "missing_counts = df.isna().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('COUNTRY\\n')\n",
    "\n",
    "missing_counts = df['Country'].isna().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "# Dropping because for this combination all other values are also missing\n",
    "df = df.drop(df[((df['ApplicationStatus'] == 'Awaiting Submission') |\n",
    "                 (df['ApplicationStatus'] == 'Awaiting Materials') |\n",
    "                 (df['ApplicationStatus'] == 'Awaiting Decision')) & (df['DecisionReason'].isnull()) & (df['Country'].isnull())].index)\n",
    "print(\"After dropping\")\n",
    "missing_counts = df['Country'].isna().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "# Fill with some value 'Others'- later can group it into category\n",
    "df['Country'].fillna('Others', inplace=True)\n",
    "\n",
    "missing_counts = df['Country'].isna().sum()\n",
    "print(\"After filling\")\n",
    "print(missing_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('VISA TYPE\\n')\n",
    "\n",
    "# Filter rows where 'VisaType' is blank (NaN)\n",
    "blank_visa_rows = df[df['VisaType'].isna()]\n",
    "\n",
    "# Get the unique 'Country' values from the filtered rows\n",
    "unique_countries = blank_visa_rows['Country'].unique()\n",
    "\n",
    "# Print the unique countries\n",
    "print(unique_countries)\n",
    "\n",
    "\n",
    "# Find the number of records where 'VisaType' is blank and 'Country' is 'United States'\n",
    "us_blank_visa_count = df.loc[(df['VisaType'].isna()) & (df['Country'] == 'United States'), 'Country'].count()\n",
    "print(f\"Number of records where 'VisaType' is blank and 'Country' is 'United States': {us_blank_visa_count}\")\n",
    "\n",
    "# Finding number of missing values in each column\n",
    "missing_counts = df['VisaType'].isna().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "# Fill 'VisaType' with 'NA  Not Applicable' where 'Country' is 'United States' and 'VisaType' is blank\n",
    "df.loc[(df['VisaType'].isna()) & (df['Country'] == 'United States'), 'VisaType'] = 'Domestic'\n",
    "\n",
    "# Finding number of missing values in each column\n",
    "missing_counts = df['VisaType'].isna().sum()\n",
    "print(\"After filling\")\n",
    "print(missing_counts)\n",
    "\n",
    "# Dropping because for this combination all other values are also missing\n",
    "df = df.drop(df[((df['ApplicationStatus'] == 'Awaiting Submission') |\n",
    "                 (df['ApplicationStatus'] == 'Awaiting Materials') |\n",
    "                 (df['ApplicationStatus'] == 'Awaiting Decision')) & (df['DecisionReason'].isnull()) & (df['VisaType'].isnull())].index)\n",
    "\n",
    "\n",
    "# Finding number of missing values in each column\n",
    "missing_counts = df['VisaType'].isna().sum()\n",
    "print(\"After dropping\")\n",
    "print(missing_counts)\n",
    "\n",
    "df['VisaType'].fillna('Other', inplace=True)\n",
    "\n",
    "# Finding number of missing values in each column\n",
    "missing_counts = df['VisaType'].isna().sum()\n",
    "print(\"After filling\")\n",
    "print(missing_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('GPA CONVERTED\\n')\n",
    "\n",
    "\n",
    "df = df[df['GPARecalculated'] != 99]  #This is exceptional case in data - so dropping\n",
    "\n",
    "# Conditionally fill 'GPAConverted' with 'GPARecalculated' where 'GPAConverted' is blank and 'GPARecalculated' is not null\n",
    "df.loc[df['GPAConverted'].isnull() & df['GPARecalculated'].notnull(), 'GPAConverted'] = df['GPARecalculated']\n",
    "missing_counts = df['GPAConverted'].isna().sum()\n",
    "print(\"After filling\")\n",
    "print(missing_counts)\n",
    "print(df.shape)\n",
    "\n",
    "# Dropping because for this combination all other values are also missing\n",
    "df = df.drop(df[((df['ApplicationStatus'] == 'Awaiting Submission') |\n",
    "                 (df['ApplicationStatus'] == 'Awaiting Materials') |\n",
    "                 (df['ApplicationStatus'] == 'Awaiting Decision')) &\n",
    "                (df['DecisionReason'].isnull()) &\n",
    "                (df['GPAConverted'].isnull())].index)\n",
    "missing_counts = df['GPAConverted'].isna().sum()\n",
    "print(\"After dropping\")\n",
    "print(missing_counts)\n",
    "\n",
    "# Calculate the average of non-null values in 'GPAConverted'\n",
    "average_gpa_converted = df['GPAConverted'].mean()\n",
    "\n",
    "\n",
    "print('average_gpa_converted',average_gpa_converted)\n",
    "# Fill blank values in 'GPAConverted' with the calculated average\n",
    "df['GPAConverted'].fillna(average_gpa_converted, inplace=True)\n",
    "\n",
    "missing_counts = df['GPAConverted'].isna().sum()\n",
    "print(\"After filling\")\n",
    "print(missing_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('DECISION RELEASED DATE\\n')\n",
    "\n",
    "\n",
    "# Convert dates in the first format\n",
    "df['ApplicationCreatedDate'] = pd.to_datetime(df['ApplicationCreatedDate'], infer_datetime_format=True)\n",
    "df['DecisionsReleasedDate'] = pd.to_datetime(df['DecisionsReleasedDate'], infer_datetime_format=True, errors='coerce')\n",
    "\n",
    "# Calculate the time differences\n",
    "df['DecisionDelayPeriod'] = df['DecisionsReleasedDate'] - df['ApplicationCreatedDate']\n",
    "\n",
    "# Calculate the average of non-null time differences\n",
    "average_time_difference = df.loc[df['DecisionDelayPeriod'].notnull(), 'DecisionDelayPeriod'].mean()\n",
    "\n",
    "\n",
    "print(\"average_time_difference\",average_time_difference)\n",
    "# Fill NaN values in 'DecisionsReleasedDate' with the calculated average\n",
    "df['DecisionsReleasedDate'].fillna(df['ApplicationCreatedDate'] + average_time_difference, inplace=True)\n",
    "\n",
    "\n",
    "missing_counts = df['DecisionsReleasedDate'].isna().sum()\n",
    "print(\"After filling\")\n",
    "print(missing_counts,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['DecisionDelayPeriod'] = df['DecisionsReleasedDate'] - df['ApplicationCreatedDate']\n",
    "\n",
    "df['DecisionDelayPeriod'] = df['DecisionDelayPeriod'].astype(str)\n",
    "\n",
    "# Preprocess the DecisionDelayPeriod column to extract the number of days\n",
    "df['DecisionDelayDays'] = df['DecisionDelayPeriod'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('DECISION REASON\\n')\n",
    "\n",
    "\n",
    "\n",
    "df['DecisionReason'].fillna('Other Reason', inplace=True)\n",
    "\n",
    "# Print the value counts of 'DecisionReason' according to the custom order\n",
    "print(df['DecisionReason'].value_counts(dropna=False))\n",
    "\n",
    "missing_counts = df['DecisionReason'].isna().sum()\n",
    "print(\"After filling\")\n",
    "print(missing_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('SCHOLARSHIP TIER\\n')\n",
    "\n",
    "\n",
    "df['ApplicationsScholarshipTierAdmit'].fillna('No Scholarship', inplace=True)\n",
    "\n",
    "missing_counts = df['ApplicationsScholarshipTierAdmit'].isna().sum()\n",
    "print(\"After filling\")\n",
    "print(missing_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('DROPPING IRRELEVANT COLUMNS\\n')\n",
    "\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "to_be_dropped_columns = ['GPARecalculated','State','PreviousDegreeInsitution','ApplicationReferralSource']\n",
    "# df = df.drop(to_be_dropped_columns, axis=1)\n",
    "\n",
    "\n",
    "# SUMMARY STATISTICS\n",
    "print('SUMMARY STATISTICS')\n",
    "print(df[continuous_vars].describe())\n",
    "\n",
    "print('CORRELATION MATRIX')\n",
    "print(df[continuous_vars].corr())\n",
    "\n",
    "\n",
    "\n",
    "# FINDING UNIQUE VALUE COUNTS IN EACH COLUMN FOR THE PURPOSE OF CATEGORISATION OF VARIABLES\n",
    "\n",
    "for col in categorical_vars:\n",
    "    print(f\"Unique value counts for column '{col}':\")\n",
    "    print(df[col].value_counts(dropna=False))\n",
    "    print()  # Print an empty line for better readability\n",
    "\n",
    "# CATEGORISING VARIABLES\n",
    "\n",
    "df['CountryUS'] = np.where(df['Country'] == \"United States\", 1,0)\n",
    "\n",
    "df['VisaRequired'] = np.where((df['VisaType'] == \"Domestic\") | (df['VisaType'] == \"NA  Not Applicable\"), 0, 1)\n",
    "\n",
    "df['ApplicationStatusDecided'] = np.where(df['ApplicationStatus'] == \"Decided\", 1,0)\n",
    "df['Scholarship(Yes)'] = np.where(df['ApplicationsScholarshipTierAdmit'] == \"No Scholarship\", 0,1)\n",
    "\n",
    "\n",
    "df['Sex(Male)'] = np.where(df['Sex'] == \"M\", 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "print('APPLICATION PROGRAM')\n",
    "\n",
    "# Create a dictionary mapping each category to its corresponding group \n",
    "# category_groups = {\n",
    "#     'Business Analytics - MSBA': 'MSBA',\n",
    "#     'Finance - MSF': 'MSF',\n",
    "#     'Business Analytics with Finance degrees - MSBA/MSF': 'JointPrograms(MSBA/MSF|MSBL/JD|MBA/JD)',\n",
    "#     'Business Administration (Professional) - MBA': 'MBA',\n",
    "#     'Sport and Entertainment Management - MBA': 'MBASportsLeadership',\n",
    "#     'Leadership Executive Master of Business Administration - MBA': 'MBASportsLeadership',\n",
    "#     'Business Administration (Professional) - MBA - Online Instruction': 'MBAOnline',\n",
    "#     'Business Analytics - MSBA - Online Instruction': 'MSBAOnline',\n",
    "#     'Business Administration - Bridge - MBA': 'MBAOthers',\n",
    "#     'Early Career Masters of Business Administration': 'MBAOthers',\n",
    "#     'Sport Business Leadership- MSBL': 'MBASportsLeadership',\n",
    "#     'Sport Business Leadership, joint Juris Doctor - MSBL/JD': 'JointPrograms(MSBA/MSF|MSBL/JD|MBA/JD)',\n",
    "#     'Business Administration (Professional), joint Juris Doctor - MBA/JD': 'JointPrograms(MSBA/MSF|MSBL/JD|MBA/JD)',\n",
    "#     'Accounting and Analytics - MS': 'MSMPAC',\n",
    "#     'Accounting (Professional) - MPAC Advanced': 'MSMPAC',\n",
    "#     'Accounting (Professional) - MPAC': 'MSMPAC',\n",
    "#     'Non-Matriculated status - Albers School of Business and Economics': 'CertificatePrograms',\n",
    "#     'Business Analytics Certificate': 'CertificatePrograms',\n",
    "#     'Executive Leadership Certificate': 'CertificatePrograms',\n",
    "#     'Leadership Formation Certificate': 'CertificatePrograms',\n",
    "#     'Marketing Certificate': 'CertificatePrograms',\n",
    "#     'Business Administration Certificate': 'CertificatePrograms',\n",
    "#     'Global Business Certificate': 'CertificatePrograms',\n",
    "#     'Finance Certificate': 'CertificatePrograms',\n",
    "#     'Accounting Certificate': 'CertificatePrograms'\n",
    "# }\n",
    "\n",
    "\n",
    "category_groups = {\n",
    "    'Business Analytics - MSBA': 'MSBA',\n",
    "    'Finance - MSF': 'Finance',\n",
    "    'Business Analytics with Finance degrees - MSBA/MSF': 'JointDegrees/CertificatePrograms',\n",
    "    'Business Administration (Professional) - MBA': 'MBA',\n",
    "    'Sport and Entertainment Management - MBA': 'MBAOthers',\n",
    "    'Leadership Executive Master of Business Administration - MBA': 'MBAOthers',\n",
    "    'Business Administration (Professional) - MBA - Online Instruction': 'MBA/MSBAOnline',\n",
    "    'Business Analytics - MSBA - Online Instruction': 'MBA/MSBAOnline',\n",
    "    'Business Administration - Bridge - MBA': 'MBAOthers',\n",
    "    'Early Career Masters of Business Administration': 'MBAOthers',\n",
    "    'Sport Business Leadership- MSBL': 'MBAOthers',\n",
    "    'Sport Business Leadership, joint Juris Doctor - MSBL/JD': 'JointDegrees/CertificatePrograms',\n",
    "    'Business Administration (Professional), joint Juris Doctor - MBA/JD': 'JointDegrees/CertificatePrograms',\n",
    "    'Accounting and Analytics - MS': 'Accounting',\n",
    "    'Accounting (Professional) - MPAC Advanced': 'Accounting',\n",
    "    'Accounting (Professional) - MPAC': 'Accounting',\n",
    "    'Non-Matriculated status - Albers School of Business and Economics': 'JointDegrees/CertificatePrograms',\n",
    "    'Business Analytics Certificate': 'JointDegrees/CertificatePrograms',\n",
    "    'Executive Leadership Certificate': 'JointDegrees/CertificatePrograms',\n",
    "    'Leadership Formation Certificate': 'JointDegrees/CertificatePrograms',\n",
    "    'Marketing Certificate': 'JointDegrees/CertificatePrograms',\n",
    "    'Business Administration Certificate': 'JointDegrees/CertificatePrograms',\n",
    "    'Global Business Certificate': 'JointDegrees/CertificatePrograms',\n",
    "    'Finance Certificate': 'JointDegrees/CertificatePrograms',\n",
    "    'Accounting Certificate': 'JointDegrees/CertificatePrograms'\n",
    "}\n",
    "\n",
    "# Create a new column to represent the grouped categories\n",
    "df['GroupedProgram'] = ''\n",
    "\n",
    "# Assign the group name to each category\n",
    "for category, group in category_groups.items():\n",
    "    df.loc[df['ApplicationProgram'].str.contains(category, regex=False), 'GroupedProgram'] = group\n",
    "\n",
    "# Create dummy variables for the grouped categories\n",
    "dummy_variables = pd.get_dummies(df['GroupedProgram'])\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df = pd.concat([df, dummy_variables], axis=1)\n",
    "\n",
    "# Drop the 'GroupedProgram' column as it's no longer needed\n",
    "df.drop(columns=['GroupedProgram'], inplace=True)\n",
    "\n",
    "print('categorised')\n",
    "\n",
    "\n",
    "print('APPLICATION START TERM')\n",
    "\n",
    "# Create a dictionary mapping each category to its corresponding group\n",
    "category_groups = {\n",
    "    'Fall 2023': 'Fall',\n",
    "    'Fall 2022': 'Fall',\n",
    "    'Fall 2024': 'Fall',\n",
    "    'Fall 2021': 'Fall',\n",
    "    'Fall 2020': 'Fall',\n",
    "    'Fall 2019': 'Fall',\n",
    "    'Fall 2018': 'Fall',\n",
    "    'Fall 2017': 'Fall',\n",
    "    'Winter 2023': 'Winter',\n",
    "    'Winter 2024': 'Winter',\n",
    "    'Winter 2022': 'Winter',\n",
    "    'Winter 2021': 'Winter',\n",
    "    'Winter 2019': 'Winter',\n",
    "    'Winter 2025': 'Winter',\n",
    "    'Winter 2020': 'Winter',\n",
    "    'Winter 2018': 'Winter',\n",
    "    'Spring 2024': 'Spring',\n",
    "    'Spring 2022': 'Spring',\n",
    "    'Spring 2023': 'Spring',\n",
    "    'Spring 2021': 'Spring',\n",
    "    'Spring 2020': 'Spring',\n",
    "    'Spring 2019': 'Spring',\n",
    "    'Spring 2025': 'Spring',\n",
    "    'Spring 2018': 'Spring',\n",
    "    'Summer 2023': 'Summer',\n",
    "    'Summer 2022': 'Summer',\n",
    "    'Summer 2021': 'Summer',\n",
    "    'Summer 2020': 'Summer',\n",
    "    'Summer 2019': 'Summer',\n",
    "    'Summer 2024': 'Summer',\n",
    "    'Summer 2017': 'Summer',\n",
    "    'Summer 2018': 'Summer'\n",
    "}\n",
    "\n",
    "# Create a new column to represent the grouped categories\n",
    "df['GroupedSeason'] = ''\n",
    "\n",
    "# Assign the group name to each category\n",
    "for category, group in category_groups.items():\n",
    "    df.loc[df['ApplicationStartTerm'].str.contains(category,regex=False), 'GroupedSeason'] = group\n",
    "\n",
    "# Create dummy variables for the grouped categories\n",
    "dummy_variables = pd.get_dummies(df['GroupedSeason'])\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df = pd.concat([df, dummy_variables], axis=1)\n",
    "\n",
    "# Drop the 'GroupedProgram' column as it's no longer needed\n",
    "# df.drop(columns=['GroupedSeason'], inplace=True)\n",
    "\n",
    "print('categorised')\n",
    "\n",
    "\n",
    "def categorize_year(year):\n",
    "  \"\"\"\n",
    "  This function assigns a category based on the extracted year.\n",
    "  \"\"\"\n",
    "  year = int(year)\n",
    "    \n",
    "  if year == 2017:\n",
    "    return '2017'\n",
    "  elif year == 2018:\n",
    "    return '2018'\n",
    "  elif year == 2019:\n",
    "    return '2019'\n",
    "  elif year == 2020:\n",
    "    return '2020'\n",
    "  elif year == 2021:\n",
    "    return '2021'\n",
    "  elif year == 2022:\n",
    "    return '2022'\n",
    "  elif year == 2023:\n",
    "    return '2023'\n",
    "  elif year == 2024:\n",
    "    return '2024'\n",
    "  else:\n",
    "    return '2025'\n",
    "\n",
    "\n",
    "#   if year in [2017, 2018, 2019, 2020]:\n",
    "#     return '2017to2020'\n",
    "#   elif year == 2021:\n",
    "#     return '2021'\n",
    "#   elif year == 2022:\n",
    "#     return '2022'\n",
    "#   elif year == 2023:\n",
    "#     return '2023'\n",
    "#   else: \n",
    "#     return '2024to2025'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract year from 'ApplicationStartTerm' and apply categorize_year function\n",
    "df['Year'] = df['ApplicationStartTerm'].str.extract('(\\d{4})', expand=False).apply(categorize_year)\n",
    "\n",
    "# Create dummy variables for each year\n",
    "year_dummies = pd.get_dummies(df['Year'])\n",
    "df = pd.concat([df, year_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'ApplicationStartTerm' column\n",
    "# df.drop('Year', axis=1, inplace=True)\n",
    "\n",
    "print(df.columns.to_numpy())\n",
    "\n",
    "print('DECISION REASON')\n",
    "\n",
    "# Create a dictionary to map each category to its respective group\n",
    "# category_groups = {\n",
    "#     'Admit Regular': 'AdmitOrDeposit',\n",
    "#     'Admit Conditional': 'AdmitOrDeposit',\n",
    "#     'Admit Probation': 'AdmitOrDeposit',\n",
    "#     'Admit Conditional & Probationary': 'AdmitOrDeposit',\n",
    "#     'Admit Conditional & Bridge': 'AdmitOrDeposit',\n",
    "#     'Deposit Paid': 'AdmitOrDeposit',\n",
    "#     'Deposit Waived/Not Required': 'AdmitOrDeposit',\n",
    "#     'Deposit - Not Required': 'AdmitOrDeposit',\n",
    "#     'Update Major - Post Decision': 'UpdateMajorOrTerm',\n",
    "#     'Update Term - Post Decision': 'UpdateMajorOrTerm',\n",
    "#     'Update Term & Major - Post Decision': 'UpdateMajorOrTerm',\n",
    "#     'Update Term - Post Enroll(CF)': 'UpdateMajorOrTerm',\n",
    "#     'Update Major - Post Enroll(CF)': 'UpdateMajorOrTerm',\n",
    "#     'Update Term & Major - Post Enroll(CF)': 'UpdateMajorOrTerm',\n",
    "#     'No Show - Post Enroll(CF)': 'UpdateMajorOrTerm',\n",
    "#     'Scholarship Adjustment': 'UpdateMajorOrTerm',\n",
    "#     'Update Term - Pre Decision': 'UpdateMajorOrTerm',\n",
    "#     'Update Term & Major - Pre Decision': 'UpdateMajorOrTerm',\n",
    "#     'Update Major - Pre Decision': 'UpdateMajorOrTerm',\n",
    "#     'Admit Declined': 'Rejected',\n",
    "#     'Admit Declined - Post Enroll(CF)': 'Rejected',\n",
    "#     'Rejected - Soft Deny': 'Rejected',\n",
    "#     'Rejected - No Alternatives': 'Rejected',\n",
    "#     'Rejected - Waitlist Deny': 'Rejected',\n",
    "#     'Waitlist Invite': 'WaitlistOrOther',\n",
    "#     'Waitlist Accepted': 'WaitlistOrOther',\n",
    "#     'Wailist Declined': 'Rejected',\n",
    "#     'Waitlist Closed': 'Rejected',\n",
    "#     'Other Reason': 'OtherReason',\n",
    "#     'Decision Delayed': 'Rejected',\n",
    "#     'Application Closed': 'ApplicationClosed',\n",
    "#     'Application Closed - Wrong Program/Duplicate Application': 'ApplicationClosed',\n",
    "#     'Application Closed - Miscellaneous': 'ApplicationClosed',\n",
    "#     'Application Closed - Fraud': 'ApplicationClosed',\n",
    "#     'Application Closed - Unrecognized/Unaccredited Inst or Prog': 'ApplicationClosed',\n",
    "#     'Application Complete - Closed': 'ApplicationClosed',\n",
    "#     'Application Incomplete - Closed': 'ApplicationClosed',\n",
    "#     'Request to Close': 'ApplicationClosed'\n",
    "# }\n",
    "\n",
    "\n",
    "category_groups = {\n",
    "    'Admit Regular': 'ApplicationSubmitted',\n",
    "    'Admit Conditional': 'ApplicationSubmitted',\n",
    "    'Admit Probation': 'ApplicationSubmitted',\n",
    "    'Admit Conditional & Probationary': 'ApplicationSubmitted',\n",
    "    'Admit Conditional & Bridge': 'ApplicationSubmitted',\n",
    "    'Deposit Paid': 'ApplicationSubmitted',\n",
    "    'Deposit Waived/Not Required': 'ApplicationSubmitted',\n",
    "    'Deposit - Not Required': 'ApplicationSubmitted',\n",
    "    'Update Major - Post Decision': 'ApplicationSubmitted',\n",
    "    'Update Term - Post Decision': 'ApplicationSubmitted',\n",
    "    'Update Term & Major - Post Decision': 'ApplicationSubmitted',\n",
    "    'Update Term - Post Enroll(CF)': 'ApplicationSubmitted',\n",
    "    'Update Major - Post Enroll(CF)': 'ApplicationSubmitted',\n",
    "    'Update Term & Major - Post Enroll(CF)': 'ApplicationSubmitted',\n",
    "    'No Show - Post Enroll(CF)': 'ApplicationSubmitted',\n",
    "    'Scholarship Adjustment': 'ApplicationSubmitted',\n",
    "    'Update Term - Pre Decision': 'ApplicationSubmitted',\n",
    "    'Update Term & Major - Pre Decision': 'ApplicationSubmitted',\n",
    "    'Update Major - Pre Decision': 'ApplicationSubmitted',\n",
    "    'Admit Declined': 'ApplicationSubmitted',\n",
    "    'Admit Declined - Post Enroll(CF)': 'ApplicationSubmitted',\n",
    "    'Rejected - Soft Deny': 'ApplicationSubmitted',\n",
    "    'Rejected - No Alternatives': 'ApplicationSubmitted',\n",
    "    'Rejected - Waitlist Deny': 'ApplicationSubmitted',\n",
    "    'Waitlist Invite': 'ApplicationSubmitted',\n",
    "    'Waitlist Accepted': 'ApplicationSubmitted',\n",
    "    'Wailist Declined': 'ApplicationSubmitted',\n",
    "    'Waitlist Closed': 'ApplicationSubmitted',\n",
    "    'Other Reason': 'Application_Not_Submitted',\n",
    "    'Decision Delayed': 'ApplicationSubmitted',\n",
    "    'Application Closed': 'Application_Not_Submitted',\n",
    "    'Application Closed - Wrong Program/Duplicate Application': 'Application_Not_Submitted',\n",
    "    'Application Closed - Miscellaneous': 'Application_Not_Submitted',\n",
    "    'Application Closed - Fraud': 'Application_Not_Submitted',\n",
    "    'Application Closed - Unrecognized/Unaccredited Inst or Prog': 'Application_Not_Submitted',\n",
    "    'Application Complete - Closed': 'Application_Not_Submitted',\n",
    "    'Application Incomplete - Closed': 'Application_Not_Submitted',\n",
    "    'Request to Close': 'Application_Not_Submitted'\n",
    "}\n",
    "\n",
    "# Create a new column to represent the grouped categories\n",
    "df['GroupedReason'] = ''\n",
    "\n",
    "# Assign the group name to each category\n",
    "for category, group in category_groups.items():\n",
    "    df.loc[df['DecisionReason'].str.contains(category, regex=False), 'GroupedReason'] = group\n",
    "\n",
    "# Create dummy variables for the grouped categories\n",
    "dummy_variables = pd.get_dummies(df['GroupedReason'])\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df = pd.concat([df, dummy_variables], axis=1)\n",
    "\n",
    "# Drop the 'GroupedProgram' column as it's no longer needed\n",
    "df.drop(columns=['GroupedReason'], inplace=True)\n",
    "\n",
    "print('categorised')\n",
    "\n",
    "\n",
    "category_groups = {\n",
    "    'Admit Regular': 'StudentAdmitted',\n",
    "    'Admit Conditional': 'StudentAdmitted',\n",
    "    'Admit Probation': 'StudentAdmitted',\n",
    "    'Admit Conditional & Probationary': 'StudentAdmitted',\n",
    "    'Admit Conditional & Bridge': 'StudentAdmitted',\n",
    "    'Deposit Paid': 'StudentAdmitted',\n",
    "    'Deposit Waived/Not Required': 'StudentAdmitted',\n",
    "    'Deposit - Not Required': 'StudentAdmitted',\n",
    "    'Update Major - Post Decision': 'StudentAdmitted',\n",
    "    'Update Term - Post Decision': 'StudentAdmitted',\n",
    "    'Update Term & Major - Post Decision': 'StudentAdmitted',\n",
    "    'Update Term - Post Enroll(CF)': 'StudentAdmitted',\n",
    "    'Update Major - Post Enroll(CF)': 'StudentAdmitted',\n",
    "    'Update Term & Major - Post Enroll(CF)': 'StudentAdmitted',\n",
    "    'No Show - Post Enroll(CF)': 'StudentAdmitted',\n",
    "    'Scholarship Adjustment': 'StudentAdmitted',\n",
    "    'Update Term - Pre Decision': 'StudentAdmitted',\n",
    "    'Update Term & Major - Pre Decision': 'StudentAdmitted',\n",
    "    'Update Major - Pre Decision': 'StudentAdmitted',\n",
    "    'Admit Declined': 'Student_Not_Admitted',\n",
    "    'Admit Declined - Post Enroll(CF)': 'Student_Not_Admitted',\n",
    "    'Rejected - Soft Deny': 'Student_Not_Admitted',\n",
    "    'Rejected - No Alternatives': 'Student_Not_Admitted',\n",
    "    'Rejected - Waitlist Deny': 'Student_Not_Admitted',\n",
    "    'Waitlist Invite': 'Student_Not_Admitted',\n",
    "    'Waitlist Accepted': 'Student_Not_Admitted',\n",
    "    'Wailist Declined': 'Student_Not_Admitted',\n",
    "    'Waitlist Closed': 'Student_Not_Admitted',\n",
    "    'Other Reason': 'Student_Not_Admitted',\n",
    "    'Decision Delayed': 'Student_Not_Admitted',\n",
    "    'Application Closed': 'Student_Not_Admitted',\n",
    "    'Application Closed - Wrong Program/Duplicate Application': 'Student_Not_Admitted',\n",
    "    'Application Closed - Miscellaneous': 'Student_Not_Admitted',\n",
    "    'Application Closed - Fraud': 'Student_Not_Admitted',\n",
    "    'Application Closed - Unrecognized/Unaccredited Inst or Prog': 'Student_Not_Admitted',\n",
    "    'Application Complete - Closed': 'Student_Not_Admitted',\n",
    "    'Application Incomplete - Closed': 'Student_Not_Admitted',\n",
    "    'Request to Close': 'Student_Not_Admitted'\n",
    "}\n",
    "\n",
    "# Create a new column to represent the grouped categories\n",
    "df['GroupReason'] = ''\n",
    "\n",
    "# Assign the group name to each category\n",
    "for category, group in category_groups.items():\n",
    "    df.loc[df['DecisionReason'].str.contains(category, regex=False), 'GroupReason'] = group\n",
    "\n",
    "# Create dummy variables for the grouped categories\n",
    "dummy_variables = pd.get_dummies(df['GroupReason'])\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df = pd.concat([df, dummy_variables], axis=1)\n",
    "\n",
    "# Drop the 'GroupedProgram' column as it's no longer needed\n",
    "df.drop(columns=['GroupReason'], inplace=True)\n",
    "\n",
    "print('categorised')\n",
    "\n",
    "print('RACE')\n",
    "# Create a new column 'RaceDummy' based on the conditions\n",
    "df['RaceDummy'] = df['Race'].apply(lambda x: 'AsianIndian' if x == 'Asian - Indian' else 'White' if x == 'White - Caucasian/European' else 'Black/African American' if x == 'Black or African American' else 'OtherRaces')\n",
    "\n",
    "print(df['RaceDummy'])\n",
    "\n",
    "# Create dummy variables for the grouped categories\n",
    "dummy_variables = pd.get_dummies(df['RaceDummy'])\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df = pd.concat([df, dummy_variables], axis=1)\n",
    "\n",
    "# Drop the 'GroupedProgram' column as it's no longer needed\n",
    "df.drop(columns=['RaceDummy'], inplace=True)\n",
    "\n",
    "print(df.columns.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a34dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print column names of the original DataFrame\n",
    "print(df.columns.to_numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Group by year and calculate the sums\n",
    "yearly_data = df.groupby('Year').agg({\n",
    "    'ApplicationSubmitted': 'sum',\n",
    "    'StudentAdmitted': 'sum',\n",
    "    'ApplicationsRegisteredinCollege': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Alternatively, you can use pivot_table\n",
    "# yearly_data = df.pivot_table(index='Year', values=['ApplicationSubmitted', 'StudentAdmitted', 'ApplicationsRegisteredinCollege'], aggfunc='sum').reset_index()\n",
    "\n",
    "yearly_data['Year'] = pd.to_numeric(yearly_data['Year'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(yearly_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1cfbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction - Polynomial fit Linear regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "degree = 3\n",
    "# Prepare the data\n",
    "X = yearly_data[['Year']]\n",
    "# X = yearly_data[['Year','ApplicationSubmitted']]\n",
    "# X = yearly_data[['Year','ApplicationSubmitted','StudentAdmitted']]\n",
    "\n",
    "\n",
    "y = yearly_data['ApplicationSubmitted']\n",
    "\n",
    "# Split the data\n",
    "X_train = X[X['Year'].isin([2019,2020,2021,2022,2023])]\n",
    "y_train = y[X['Year'].isin([2019,2020,2021,2022,2023])]\n",
    "\n",
    "# X_train=X[~X['Year'].isin([2024, 2025])]\n",
    "# y_train = y[~X['Year'].isin([2024, 2025])]\n",
    "X_test=X[X['Year'].isin([2024, 2025])]\n",
    "\n",
    "# # Fit the linear regression model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# Polynomial features\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Fit the polynomial regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict the values for 2024 and 2025\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(X_train, y_train, color='blue', label='Training Data')\n",
    "plt.scatter(X_test, y_pred, color='red', label='Predicted Test Data')\n",
    "plt.plot(X_train, model.predict(X_train_poly), color='green', label='Polynomial Fit')\n",
    "plt.xlabel('Year')\n",
    "# plt.ylabel('Number of Applications Submitted')\n",
    "# plt.title('Application Submitted over Years')\n",
    "plt.ylabel('Number of Applications registerd in college')\n",
    "plt.title('Application registered over Years')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create a DataFrame to display the predicted values\n",
    "# predicted_data = pd.DataFrame({'Year': X_pred.flatten(), 'Predicted_ApplicationSubmitted': y_pred})\n",
    "print(y_pred)\n",
    "\n",
    "# yearly_data.loc[yearly_data['Year'] == 2024, 'StudentAdmitted'] = round(y_pred[0],0)\n",
    "# yearly_data.loc[yearly_data['Year'] == 2025, 'StudentAdmitted'] = round(y_pred[1],0)\n",
    "# print(yearly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50475549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # LOGISTIC MODEL\n",
    "\n",
    "df['intercept'] = 1.0\n",
    "\n",
    "# df_program = df.loc[df['MSBA'] == 1]\n",
    "df_program = df\n",
    "print(df_program.shape)\n",
    "\n",
    "y=df_program['ApplicationsRegisteredinCollege']\n",
    "X=df_program[['intercept', 'Age',\n",
    " 'DecisionDelayDays', 'CountryUS', 'Scholarship(Yes)','Sex(Male)', 'StudentAdmitted', 'AsianIndian', 'Black/African American',\n",
    " 'OtherRaces']]\n",
    "\n",
    "\n",
    "# Reference Variables:\n",
    "# 'Finance/Accounting' 'JointDegrees/CertificatePrograms' 'MBA'\n",
    "#  'MBA/MSBAOnline' 'MBAOthers' 'MSBA'\n",
    "# Student_Not_Admitted\n",
    "# OtherRaces\n",
    "# 2017to2020\n",
    "# include 'ApplicationSubmitted', 'Application_Not_Submitted' for another model\n",
    "# Sex(Male)\n",
    "\n",
    "\n",
    "for column in df_program.columns:\n",
    "    unique_counts = df_program[column].value_counts()\n",
    "    print(f\"'{column}':\")\n",
    "    print(unique_counts)\n",
    "\n",
    "    \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=109)\n",
    "\n",
    "\n",
    "logit_model = sm.Logit(y_train, X_train).fit()\n",
    "print(logit_model.summary())\n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_train_pred = logit_model.predict(X_train)\n",
    "y_train_pred_binary = (y_train_pred > 0.5).astype(int) \n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred_binary, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred_binary)\n",
    "precision_train = precision_score(y_train, y_train_pred_binary)\n",
    "recall_train = recall_score(y_train, y_train_pred_binary)\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "y_pred = logit_model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Converting probabilities to binary predictions\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred_binary,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
    "max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "min_samples_leaf=10, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, random_state=100, splitter='best')\n",
    " \n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "tree.plot_tree(clf, feature_names=['intercept',  'Age',\n",
    " 'DecisionDelayDays', 'CountryUS', 'Scholarship(Yes)', 'Sex(Male)', 'StudentAdmitted', 'AsianIndian', 'Black/African American',\n",
    " 'OtherRaces'])\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred, average='macro')\n",
    "#precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred,average='macro')\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred,average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a764910d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Confusion Matrix**\n",
      " [[1653  151]\n",
      " [  81  338]]\n",
      "\n",
      "**Classification Report**\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      1804\n",
      "           1       0.69      0.81      0.74       419\n",
      "\n",
      "    accuracy                           0.90      2223\n",
      "   macro avg       0.82      0.86      0.84      2223\n",
      "weighted avg       0.90      0.90      0.90      2223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "\n",
    "np.unique(y, return_counts=True)\n",
    " \n",
    "# Scale the data so that no one feature gets dominated \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    " \n",
    "# Divide the data for training and testing\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y, test_size=.3, \n",
    "                                                random_state=1234, stratify=y)\n",
    " \n",
    "# Make an instance of the KNeighborsClassifier class\n",
    "knnc = KNeighborsClassifier()\n",
    "# The default number of neighbors is 5.  Try different numbers and see how\n",
    "# the different models perform. \n",
    "# knnc = KNeighborsClassifier(n_neighbors=1)\n",
    "# knnc = KNeighborsClassifier(n_neighbors=5)\n",
    "# knnc = KNeighborsClassifier(n_neighbors=7)\n",
    "# Fit the k-nearest neighbors classifier from the training dataset.\n",
    "knnc.fit(X_train, y_train)\n",
    "# Make predictions using the test data\n",
    "y_pred_knnc = knnc.predict(X_test)\n",
    "# Build a confusion matrix and show the Classification Report\n",
    "cm_knnc = confusion_matrix(y_test,y_pred_knnc)\n",
    "print('\\n**Confusion Matrix**\\n',cm_knnc)\n",
    "print('\\n**Classification Report**\\n')\n",
    "print(classification_report(y_test,y_pred_knnc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66952546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=109)\n",
    "\n",
    "# Fit linear regression model\n",
    "linear_model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Print summary of the model\n",
    "print(linear_model.summary())\n",
    "\n",
    "# Prediction\n",
    "y_train_pred = linear_model.predict(X_train)\n",
    "y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training R^2:\", train_r2)\n",
    "\n",
    "print(\"Testing MSE:\", test_mse)\n",
    "print(\"Testing R^2:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58af3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.to_numpy())\n",
    "\n",
    "def scatter_histogram_bar(df, x_var, y_var):\n",
    "    # Extract the relevant data\n",
    "    x_data = df[x_var]\n",
    "    y_data = df[y_var]\n",
    "\n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.scatter(x_data, y_data, alpha=0.5)\n",
    "    plt.title(f'Scatter plot of {x_var} vs {y_var}')\n",
    "    plt.xlabel(x_var)\n",
    "    plt.ylabel(y_var)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Create a histogram\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.hist(x_data, bins=30, edgecolor='k')\n",
    "    plt.title(f'Histogram of {x_var}')\n",
    "    plt.xlabel(x_var)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "\n",
    " \n",
    "# Example usage:\n",
    "scatter_histogram_bar(df, 'Age', 'ApplicationsRegisteredinCollege')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
