{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c144d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"airData_cleaned.csv\")\n",
    "\n",
    "colNames = df.columns.to_numpy()  # Convert to NumPy array\n",
    "print(colNames)\n",
    "summary = df.describe()\n",
    "print(summary)\n",
    "\n",
    "any_na = df.isna().any()\n",
    "\n",
    "# Print columns with NaN values, if any\n",
    "if any_na.any():\n",
    "    columns_with_na = any_na[any_na].index\n",
    "    print(\"Columns with NaN values:\")\n",
    "    for col in columns_with_na:\n",
    "        num_na = df[col].isna().sum()\n",
    "        print(f\"{col}: {num_na}\")\n",
    "else:\n",
    "    print(\"No columns have NaN values.\")\n",
    "df.shape\n",
    "\n",
    "# Cleaned data in excel for Gender(filled with Male), FrequentFlightDestination(Picked one value from multiple values(used max repeating value in Airline-Destination combination))- done manually in Excel\n",
    "df = df[df['Airline'].notnull()]\n",
    "df = df[df['Destination'] != 4]\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n",
    "# FUNCTION TO PRINT UNIQUE COMBINATIONS FOR A  GIVEN SET OF FEATURES\n",
    "def print_unique_combinations(variable_names):\n",
    "    \"\"\"\n",
    "    Print unique combinations of variables along with their counts in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    variable_names : list of str\n",
    "        A list of variable names for which unique combinations and counts are to be printed.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - This function prints the unique combinations of variables specified by variable_names along with their counts.\n",
    "    - It retrieves the unique combinations and their counts using value_counts() function applied to the DataFrame.\n",
    "    - The output is printed in a tabular format where each row represents a unique combination of variables along with its count.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> print_unique_combinations(['Airline','Destination'])\n",
    "    \"\"\"\n",
    "\n",
    "    unique_combinations = df[variable_names].value_counts().reset_index()\n",
    "    unique_combinations = unique_combinations.rename(columns={0: 'count'})\n",
    "    print(unique_combinations)\n",
    "\n",
    "    \n",
    "    \n",
    "# FUNCTION TO FILL MISSING DATA FOR A GIVEN VARIABLE(REFERENCE VARIABLE) BASED ON ONE RELATED VARIABLE\n",
    "def impute_missing_data_one(reference_variable, variable_names, threshold):\n",
    "    \"\"\"\n",
    "    Impute missing values in a DataFrame based on a reference variable and related variables.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    reference_variable : str\n",
    "        The variable containing missing values to be imputed.\n",
    "    variable_names : list of str\n",
    "        A list of variable names used to identify unique combinations.\n",
    "    threshold : int\n",
    "        The minimum count threshold for considering a combination of variables.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - This function imputes missing values in the DataFrame based on the average value of the reference_variable\n",
    "      for unique combinations of variable_names.\n",
    "    - It prints the unique combinations of variable_names and their counts, filtered combinations based on the threshold,\n",
    "      and the average values calculated for filtered combinations.\n",
    "    - Finally, it updates the DataFrame with the imputed values and prints the remaining null values in the reference_variable.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> impute_missing_data_one('Airfare','Airline',81)\n",
    "    \"\"\"\n",
    "    missing_rows = df[df[reference_variable].isnull()]\n",
    "    unique_combinations = df[variable_names].value_counts()\n",
    "    print(unique_combinations)\n",
    "\n",
    "    # Filter combinations based on the threshold\n",
    "    filtered_combinations = unique_combinations[unique_combinations >= threshold].index\n",
    "\n",
    "    # Calculate average value for each filtered combination\n",
    "    average_values = df.groupby(variable_names)[reference_variable].mean().loc[filtered_combinations].round()\n",
    "    \n",
    "    average_values = average_values.rename(f'average_{reference_variable}')\n",
    "    print(\"\\nAVERAGE VALUES\\n\")\n",
    "    print(average_values)\n",
    "\n",
    "      \n",
    "    df.loc[missing_rows.index, reference_variable] = missing_rows.apply(\n",
    "    lambda row: average_values.loc[(row[variable_names])] if (row[variable_names]) in average_values.index else row[reference_variable],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "    # Print the updated DataFrame shape\n",
    "    print(f\"\\nNull values remaining in {reference_variable} after imputation:\\n\", df[df[reference_variable].isnull()].shape)\n",
    "    missing_rows = df[df[reference_variable].isnull()]\n",
    "    print(missing_rows)\n",
    "    print(\"Shape of DataFrame:\", df.shape)\n",
    "\n",
    "\n",
    "    \n",
    "# FUNCTION TO FILL MISSING DATA FOR A GIVEN VARIABLE(REFERENCE VARIABLE) BASED ON MANY RELATED VARIABLES\n",
    "def impute_missing_data_many(reference_variable, variable_names, threshold):\n",
    "    \"\"\"\n",
    "    Impute missing values in a DataFrame based on a reference variable and multiple related variables.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    reference_variable : str\n",
    "        The variable containing missing values to be imputed.\n",
    "    variable_names : list of str\n",
    "        A list of variable names used to identify unique combinations.\n",
    "    threshold : int\n",
    "        The minimum count threshold for considering a combination of variables.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - This function imputes missing values in the DataFrame based on the average value of the reference_variable\n",
    "      for unique combinations of variable_names.\n",
    "    - It prints the unique combinations of variable_names and their counts, filtered combinations based on the threshold,\n",
    "      and the average values calculated for filtered combinations.\n",
    "    - Finally, it updates the DataFrame with the imputed values and prints the remaining null values in the reference_variable.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> impute_missing_data_many('Airfare',['Airline','Destination'],24) \n",
    "    \"\"\"\n",
    "    missing_rows = df[df[reference_variable].isnull()]\n",
    "    unique_combinations = df[variable_names].value_counts()\n",
    "    print(unique_combinations)\n",
    "\n",
    "    # Filter combinations based on the threshold\n",
    "    filtered_combinations = unique_combinations[unique_combinations >= threshold].index\n",
    "\n",
    "    # Calculate average value for each filtered combination\n",
    "    average_values = df.groupby(variable_names)[reference_variable].mean().loc[filtered_combinations].round()\n",
    "    average_values = average_values.rename(f'average_{reference_variable}')\n",
    "\n",
    "    \n",
    "    print(\"\\nAVERAGE VALUES\\n\")\n",
    "    print(average_values)\n",
    "\n",
    "      \n",
    "    df.loc[missing_rows.index, reference_variable] = missing_rows.apply(\n",
    "    lambda row: average_values.loc[(row[variable_names[0]],row[variable_names[1]])] if (row[variable_names[0]],row[variable_names[1]]) in average_values.index else row[reference_variable],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "    # Print the updated DataFrame shape\n",
    "    print(f\"\\nNull values remaining in {reference_variable} after imputation:\\n\", df[df[reference_variable].isnull()].shape)\n",
    "    missing_rows = df[df[reference_variable].isnull()]\n",
    "    print(missing_rows)\n",
    "    print(\"Shape of DataFrame:\", df.shape)\n",
    "\n",
    "\n",
    "    \n",
    "# FILLING MISSING VALUES USING OTHER RELEVANT COMBINATIONS\n",
    "\n",
    "\n",
    "# AIRFARE:\n",
    "\n",
    "print_unique_combinations(['Airline','Destination'])\n",
    "impute_missing_data_many('Airfare',['Airline','Destination'],24) \n",
    "print_unique_combinations('Airline')\n",
    "impute_missing_data_one('Airfare','Airline',81)\n",
    "\n",
    "print(df.loc[471, 'Airfare'])\n",
    "\n",
    "\n",
    "\n",
    "# Income - Occupation, SeatClass\n",
    "\n",
    "print_unique_combinations(['Occupation','SeatClass'])\n",
    "impute_missing_data_many('Income',['Occupation','SeatClass'],24) \n",
    "print_unique_combinations('Occupation')\n",
    "impute_missing_data_one('Income','Occupation', 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Departure_Hr - Departure_Time, Airlines\n",
    "\n",
    "print_unique_combinations(['DepartureTime','Airline'])\n",
    "impute_missing_data_many('DepartureHr',['DepartureTime','Airline'],10) \n",
    "print_unique_combinations('DepartureTime')\n",
    "impute_missing_data_one('DepartureHr','DepartureTime',25) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# AccessTime - ModeTransport, Airport,Departure_Time\n",
    "\n",
    "print_unique_combinations(['ModeTransport','Airport'])\n",
    "impute_missing_data_many('AccessTime',['ModeTransport','Airport'],15) \n",
    "print_unique_combinations('Airport')\n",
    "impute_missing_data_one('AccessTime','Airport',1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Destination - Airport, Airline, DepartureTime\n",
    "\n",
    "print_unique_combinations(['Airline','DepartureTime'])\n",
    "impute_missing_data_many('Destination',['Airline','DepartureTime'],15) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check if any column contains NaN values\n",
    "any_na = df.isna().any()\n",
    "\n",
    "# Find out the number of missing values in each column\n",
    "missing_counts = df.isna().sum()\n",
    "\n",
    "# Calculate the percentage of missing values for each column\n",
    "total_rows = len(df)\n",
    "percent_missing = (missing_counts / total_rows) * 100\n",
    "\n",
    "# Create a list of lists to hold the data\n",
    "table_data = []\n",
    "if any_na.any():\n",
    "    for col in any_na.index[any_na]:\n",
    "        table_data.append([col, missing_counts[col], f\"{percent_missing[col]:.2f}%\"])\n",
    "\n",
    "\n",
    "print(\"\\nColumns with missing values > 30%: \\n\")\n",
    "filtered_cols = percent_missing[percent_missing > 30]\n",
    "print(filtered_cols)\n",
    "\n",
    "columns_to_drop = ['ID','FlightNo','AccessCost', 'MileageAirline', 'Mileage','DepartureMn']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#CALCULATING CHOICE PROBABLITIES (AIRPORT)\n",
    "\n",
    "# FUNCTION TO CALCULATE CHOICE PROBABILITIES FOR CATEGORICAL VARIABLES (AIRPORT MODEL)\n",
    "def calculate_gini_probabilities(df, variable_name, num_categories):\n",
    "    \"\"\"\n",
    "    Calculate probabilities and observations count for each category of a variable, \n",
    "    considering the occurrences in different airport categories.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    variable_name : str\n",
    "        The name of the variable for which probabilities and counts are to be calculated.\n",
    "    num_categories : int\n",
    "        The number of categories in the variable.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - This function calculates the probabilities of each category of the variable considering the occurrences\n",
    "      in different airport categories.\n",
    "    - It counts the occurrences of each variable-airport combination and calculates the probabilities\n",
    "      based on the total occurrences of each variable category.\n",
    "    - The probabilities are rounded to one decimal place.\n",
    "    - The function also prints the count of each variable-airport combination and the resulting probabilities\n",
    "      along with the total number of observations in each category of the variable.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> calculate_gini_probabilities(df, 'Airline', 4)  \n",
    "    \"\"\"\n",
    "   \n",
    "    # Count occurrences of each variable-airport combination\n",
    "    variable_airport_counts = df.groupby([variable_name, 'Airport']).size().unstack(fill_value=0)\n",
    "    print(\"\\nCOUNT OF {}-AIRPORT COMBINATIONS\\n\".format(variable_name.upper()))\n",
    "    print(variable_airport_counts)\n",
    "    \n",
    "    variable_airport_probabilities = variable_airport_counts.div(variable_airport_counts.sum(axis=1), axis=0).round(1)\n",
    "\n",
    "    variable_counts = df[variable_name].value_counts()\n",
    "    \n",
    "    # Sort the index of variable_airport_probabilities dataframe\n",
    "    variable_airport_probabilities_sorted = variable_airport_probabilities.sort_index()\n",
    "    \n",
    "    # Concatenate probabilities and Number of Observations in each category of variable\n",
    "    result = pd.concat([variable_airport_probabilities_sorted, variable_counts], axis=1)\n",
    "    \n",
    "    # Rename the count column\n",
    "    result.rename(columns={variable_name: 'No_Of_Observations'}, inplace=True)\n",
    "    \n",
    "    # Print the result\n",
    "    print(\"\\nProbabilities along with Total no of observations\\n\")\n",
    "    print(result)\n",
    "\n",
    "calculate_gini_probabilities(df, 'Airline', 4)  \n",
    "calculate_gini_probabilities(df, 'Gender', 2)  \n",
    "calculate_gini_probabilities(df, 'Nationality', 5)  \n",
    "calculate_gini_probabilities(df, 'TripPurpose', 4)  \n",
    "calculate_gini_probabilities(df, 'ProvinceResidence', 8)  \n",
    "calculate_gini_probabilities(df, 'GroupTravel', 2)  \n",
    "calculate_gini_probabilities(df, 'FrequentFlightDestination', 7)  \n",
    "calculate_gini_probabilities(df, 'Destination', 3) \n",
    "calculate_gini_probabilities(df, 'DepartureTime', 4)  \n",
    "calculate_gini_probabilities(df, 'SeatClass', 3)  \n",
    "calculate_gini_probabilities(df, 'ModeTransport', 11)  \n",
    "calculate_gini_probabilities(df, 'Occupation', 12)  \n",
    "calculate_gini_probabilities(df, 'Income', 7)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION TO CALCULATE CHOICE PROBABILITIES FOR CONTINUOS VARIABLES (AIRPORT MODEL)\n",
    "def calculate_gini_probabilities_continuous(df, variable_name):\n",
    "       \n",
    "    # Calculate the mean of the continuous variable for each airport category\n",
    "    mean_variable_airport = df.groupby('Airport')[variable_name].mean()\n",
    "    print(\"\\nMEAN VALUE OF {} FOR EACH AIRPORT\\n\".format(variable_name.upper()))\n",
    "    print(mean_variable_airport)\n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "calculate_gini_probabilities_continuous(df, 'Age')  \n",
    "calculate_gini_probabilities_continuous(df, 'TripDuration') \n",
    "calculate_gini_probabilities_continuous(df, 'FlyingCompanion')  \n",
    "calculate_gini_probabilities_continuous(df, 'NoTripsLastYear')  \n",
    "calculate_gini_probabilities_continuous(df, 'DepartureHr')  \n",
    "calculate_gini_probabilities_continuous(df, 'Airfare')\n",
    "calculate_gini_probabilities_continuous(df, 'NoTransport')  \n",
    "calculate_gini_probabilities_continuous(df, 'AccessTime')  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#CALCULATING CHOICE PROBABLITIES (AIRLINE)\n",
    "\n",
    "\n",
    "df['Airline_Category'] = df['Airline'].map({1: 1, 2: 2, 3: 1, 4: 2})\n",
    "\n",
    "# FUNCTION TO CALCULATE CHOICE PROBABILITIES FOR CATEGORICAL VARIABLES (AIRLINE MODEL)\n",
    "def calculate_gini_probabilities_Airlines(df, variable_name, num_categories):\n",
    "   \n",
    "    # Count occurrences of each variable-airport combination\n",
    "    variable_airline_counts = df.groupby([variable_name, 'Airline_Category']).size().unstack(fill_value=0)\n",
    "    print(\"\\nCOUNT OF {}-Airline COMBINATIONS\\n\".format(variable_name.upper()))\n",
    "    print(variable_airline_counts)\n",
    "    \n",
    "    variable_airline_probabilities = variable_airline_counts.div(variable_airline_counts.sum(axis=1), axis=0).round(1)\n",
    "\n",
    "    variable_counts = df[variable_name].value_counts()\n",
    "    \n",
    "    # Sort the index of variable_airport_probabilities dataframe\n",
    "    variable_airline_probabilities_sorted = variable_airline_probabilities.sort_index()\n",
    "    \n",
    "    # Concatenate probabilities and Number of Observations in each category of variable\n",
    "    result = pd.concat([variable_airline_probabilities_sorted, variable_counts], axis=1)\n",
    "    \n",
    "    # Rename the count column\n",
    "    result.rename(columns={variable_name: 'No_Of_Observations'}, inplace=True)\n",
    "    \n",
    "    # Print the result\n",
    "    print(\"\\nProbabilities along with Total no of observations\\n\")\n",
    "    print(result)\n",
    "\n",
    "calculate_gini_probabilities_Airlines(df, 'Airport', 4)  \n",
    "calculate_gini_probabilities_Airlines(df, 'Gender', 2)  \n",
    "calculate_gini_probabilities_Airlines(df, 'Nationality', 5)  \n",
    "calculate_gini_probabilities_Airlines(df, 'TripPurpose', 4)  \n",
    "calculate_gini_probabilities_Airlines(df, 'ProvinceResidence', 8)  \n",
    "calculate_gini_probabilities_Airlines(df, 'GroupTravel', 2)  \n",
    "calculate_gini_probabilities_Airlines(df, 'FrequentFlightDestination', 7)  \n",
    "calculate_gini_probabilities_Airlines(df, 'Destination', 3) \n",
    "calculate_gini_probabilities_Airlines(df, 'DepartureTime', 4)  \n",
    "calculate_gini_probabilities_Airlines(df, 'SeatClass', 3)  \n",
    "calculate_gini_probabilities_Airlines(df, 'ModeTransport', 11)  \n",
    "calculate_gini_probabilities_Airlines(df, 'Occupation', 12)  \n",
    "calculate_gini_probabilities_Airlines(df, 'Income', 7)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION TO CALCULATE CHOICE PROBABILITIES FOR CONTINUOS VARIABLES (AIRPORT MODEL)\n",
    "def calculate_gini_probabilities_continuous_Airlines(df, variable_name):\n",
    "       \n",
    "    # Calculate the mean of the continuous variable for each airport category\n",
    "    mean_variable_airline = df.groupby('Airline_Category')[variable_name].mean()\n",
    "    print(\"\\nMEAN VALUE OF {} FOR EACH Airline\\n\".format(variable_name.upper()))\n",
    "    print(mean_variable_airline)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "calculate_gini_probabilities_continuous_Airlines(df, 'Age')  \n",
    "calculate_gini_probabilities_continuous_Airlines(df, 'TripDuration') \n",
    "calculate_gini_probabilities_continuous_Airlines(df, 'FlyingCompanion')  \n",
    "calculate_gini_probabilities_continuous_Airlines(df, 'NoTripsLastYear')  \n",
    "calculate_gini_probabilities_continuous_Airlines(df, 'DepartureHr')  \n",
    "calculate_gini_probabilities_continuous_Airlines(df, 'Airfare')\n",
    "calculate_gini_probabilities_continuous_Airlines(df, 'NoTransport')  \n",
    "calculate_gini_probabilities_continuous_Airlines(df, 'AccessTime')  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ANOVA TEST\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "\n",
    "column_headers = df.columns.tolist()\n",
    "for i in column_headers:\n",
    "    group1 = df[df['Airport'] == 1][i]\n",
    "    group2 = df[df['Airport'] == 2][i]\n",
    "\n",
    "    # Perform ANOVA\n",
    "    f_statistic, p_value = stats.f_oneway(group1, group2)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Airport vs \" +i)\n",
    "    print(\"F-statistic:\", f_statistic)\n",
    "    print(\"P-value:\", p_value)\n",
    "\n",
    "\n",
    "\n",
    "for i in column_headers:\n",
    "    group1 = df[df['Airline'] == 1][i]\n",
    "    group2 = df[df['Airline'] == 2][i]\n",
    "\n",
    "    # Perform ANOVA\n",
    "    f_statistic, p_value = stats.f_oneway(group1, group2)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Airline vs \" +i)\n",
    "    print(\"F-statistic:\", f_statistic)\n",
    "    print(\"P-value:\", p_value)\n",
    "\n",
    "                                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTS\n",
    "\n",
    "# Plot distribution of passengers between the two airports\n",
    "\n",
    "airport_counts = df['Airport'].value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(airport_counts.index, airport_counts.values, color=['lightgreen'])\n",
    "plt.title('Distribution of Passengers between Airports')\n",
    "plt.xlabel('Airport')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(airport_counts.index, ['Airport-Inchoen', 'Airport-Gimpo'])\n",
    "plt.show()\n",
    "\n",
    "# Plot distribution of passengers between the two airlines\n",
    "airline_counts = df['Airline_Category'].value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(airline_counts.index, airline_counts.values, color=['orange'])\n",
    "plt.title('Distribution of Passengers between Airlines')\n",
    "plt.xlabel('Airline Category')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(airline_counts.index, ['Airline-Korean', 'Airline-Others'])\n",
    "plt.show()\n",
    "\n",
    "df['Airline_Category1'] = df['Airline'].map({1: \"Korean\", 2: \"Others\", 3: \"Korean\", 4: \"Others\"})\n",
    "df['Airport_Category1'] = df['Airline'].map({1: \"Incheon\", 2: \"Gimpo\"})\n",
    "\n",
    "\n",
    "# Plot Destination vs. Airport\n",
    "plt.figure(figsize=(10, 6))\n",
    "destination_counts = df['Destination'].value_counts()\n",
    "airport_counts = df.groupby('Destination')['Airport_Category1'].value_counts().unstack(fill_value=0)\n",
    "airport_counts.plot(kind='bar', ax=plt.gca(), color=['skyblue', 'lightgreen', 'salmon'], width=0.8)\n",
    "plt.title('Destination vs. Airport')\n",
    "plt.xlabel('Destination')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(range(len(destination_counts)), ['China', 'Japan', 'South-East Asia'])  \n",
    "plt.legend(title='Airport')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Destination vs. Airline Category\n",
    "plt.figure(figsize=(10, 6))\n",
    "airline_counts = df.groupby('Destination')['Airline_Category1'].value_counts().unstack(fill_value=0)\n",
    "airline_counts.plot(kind='bar', ax=plt.gca(), color=['skyblue', 'lightgreen'], width=0.8)\n",
    "plt.title('Destination vs. Airline Category')\n",
    "plt.xlabel('Destination')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(range(len(destination_counts)), ['China', 'Japan', 'South-East Asia']) \n",
    "plt.legend(title='Airline Category')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot Income vs. Airport\n",
    "plt.figure(figsize=(10, 6))\n",
    "income_counts = df['Income'].value_counts()\n",
    "airport_counts = df.groupby('Income')['Airport_Category1'].value_counts().unstack(fill_value=0)\n",
    "airport_counts.plot(kind='bar', ax=plt.gca(), width=0.8)\n",
    "plt.title('Income vs. Airport')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(range(len(income_counts)), income_counts.index)  \n",
    "plt.legend(title='Airport')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Income vs. Airline Category\n",
    "plt.figure(figsize=(10, 6))\n",
    "airline_counts = df.groupby('Income')['Airline_Category1'].value_counts().unstack(fill_value=0)\n",
    "airline_counts.plot(kind='bar', ax=plt.gca(), width=0.8)\n",
    "plt.title('Income vs. Airline Category')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.xticks(range(len(income_counts)), income_counts.index)  \n",
    "plt.legend(title='Airline Category')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d321df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION MODEL(AIRPORT)\n",
    "\n",
    "#Age\n",
    "df['AccessTime<=40'] = np.where(df['AccessTime'] <= 40, 1, 0)\n",
    "df['AccessTime>40'] = np.where(df['AccessTime'] > 40, 1, 0)\n",
    "\n",
    "#TripDuration\n",
    "df['TripDuration<=7'] = np.where(df['TripDuration'] <= 7, 1, 0)\n",
    "df['TripDuration>7'] = np.where(df['TripDuration'] > 7, 1, 0)\n",
    "\n",
    "\n",
    "#NoTripsLastYear\n",
    "df['NoTripsLastYear<=3'] = np.where(df['NoTripsLastYear'] <= 3, 1, 0)\n",
    "df['NoTripsLastYear>3'] = np.where(df['NoTripsLastYear'] > 3, 1, 0)\n",
    "\n",
    "\n",
    "#Creating dummy variables for Airline\n",
    "df['Airline(Korean)'] = np.where(df['Airline'].isin([1,3]), 1, 0)\n",
    "df['Airline(Asiana and Foreign)'] = np.where(df['Airline'].isin([2,4]), 1, 0)\n",
    "\n",
    "\n",
    "#Creating dummy variables for Gender\n",
    "df['Male'] = np.where(df['Gender']== 1, 1, 0)\n",
    "df['Female'] = np.where(df['Gender']== 2, 1, 0)\n",
    "\n",
    "#Creating dummy variables for Nationality\n",
    "df['Nationality(Korean and Other)'] = np.where(df['Nationality'].isin([1,4,5]), 1, 0)\n",
    "df['Nationality(China)'] = np.where(df['Nationality'].isin([2]), 1, 0)\n",
    "df['Nationality(Japan)'] = np.where(df['Nationality'].isin([3]), 1, 0)\n",
    "\n",
    "\n",
    "#Creating dummy variables for TripPurpose      \n",
    "df['TripPurpose-Leisure'] = np.where(df['TripPurpose'].isin([1]), 1, 0)\n",
    "df['TripPurpose-Business,Study, Other'] = np.where(df['TripPurpose'].isin([2, 3,4]), 1, 0)\n",
    "\n",
    "    \n",
    "#Creating dummy variables for ProvinceResidence\n",
    "df['PR-Seoul,Others'] = np.where(df['ProvinceResidence'].isin([1,8]), 1, 0)\n",
    "df['PR-Incheon,Kyungki,Chungcheong,Kangwon'] = np.where(df['ProvinceResidence'].isin([2, 3, 4, 7,5, 6]), 1, 0) #Reference\n",
    "\n",
    "\n",
    "#Creating dummy variables for DepartureTime\n",
    "df['Morning'] = np.where(df['DepartureTime'] == 1, 1, 0)\n",
    "df['Afternoon'] = np.where(df['DepartureTime'] == 2, 1, 0)\n",
    "df['Evening'] = np.where(df['DepartureTime'] == 3, 1, 0)\n",
    "df['Night'] = np.where(df['DepartureTime'] == 4, 1, 0)\n",
    "\n",
    "\n",
    "# Creating dummy variables for FrequentFlightDestination\n",
    "df['FFD-SouthEast Asia'] = np.where(df['FrequentFlightDestination'].isin([1]), 1, 0)\n",
    "df['FFD-China,Others'] = np.where(df['FrequentFlightDestination'].isin([2,6]), 1, 0)\n",
    "df['FFD-Japan'] = np.where(df['FrequentFlightDestination'].isin([3]), 1, 0)\n",
    "df['FFD-North & South America'] = np.where(df['FrequentFlightDestination'].isin([4]), 1, 0)\n",
    "df['FFD-Europe & None'] = np.where(df['FrequentFlightDestination'].isin([5,7]), 1, 0)\n",
    "\n",
    "\n",
    "#Creating dummy variables for Destination\n",
    "df['Destination-China'] = np.where(df['Destination'] == 1, 1, 0)\n",
    "df['Destination-Japan'] = np.where(df['Destination'].isin([2]), 1, 0)\n",
    "df['Destination-SouthEast Asia'] = np.where(df['Destination'] == 3, 1, 0)\n",
    "\n",
    "\n",
    "df['DepartureHr<=15'] = np.where(df['DepartureHr'] <= 15, 1, 0)\n",
    "df['DepartureHr>15'] = np.where(df['DepartureHr'] > 15, 1, 0)  #reference\n",
    "\n",
    "#Creating dummy variables for SeatClass\n",
    "df['Economy'] = np.where(df['SeatClass'] == 1, 1, 0)\n",
    "df['Business & First'] = np.where(df['SeatClass'].isin([2, 3]), 1, 0)\n",
    "\n",
    "#Creating dummy variables for ModeTransport\n",
    "df['ModeTransport1'] = np.where(df['ModeTransport'].isin([5,1,2,11]), 1, 0)\n",
    "df['ModeTransport2'] = np.where(df['ModeTransport'].isin([3,4,6,9,10]), 1, 0)\n",
    "df['ModeTransport3'] = np.where(df['ModeTransport'].isin([7,8]), 1, 0)\n",
    "#df['ModeTransport4'] = np.where(df['ModeTransport'].isin([11]), 1, 0)\n",
    "\n",
    "\n",
    "#Creating dummy variables for Occupation\n",
    "df['OCC-Group1'] = np.where(df['Occupation'].isin([1,8,9,10,11]), 1, 0)\n",
    "df['OCC-Group2'] = np.where(df['Occupation'].isin([2,4,5,6,7]), 1, 0)                           \n",
    "df['OCC-Group3'] = np.where(df['Occupation'].isin([3,12]), 1, 0)\n",
    "#df['OCC-Group4'] = np.where(df['Occupation'].isin([6,10]), 1, 0)  \n",
    "\n",
    "\n",
    "#Creating dummy variables for Income\n",
    "df['Income-Group1'] = np.where(df['Income'].isin([3]), 1, 0)\n",
    "df['Income-Group2'] = np.where(df['Income'].isin([2,4,5,6,7]), 1, 0)  \n",
    "df['Income-Group2'] = np.where(df['Income'].isin([1]), 1, 0)  \n",
    "\n",
    "\n",
    "# LOGISTIC REGRESSION MODEL (AIRPORT)\n",
    "\n",
    "df['intercept'] = 1.0\n",
    "\n",
    "df['Airport(Inchoen)'] = df['Airport'].map({1: 1, 2: 0})\n",
    "df['GroupTravelYes']=df['GroupTravel'].astype('category').cat.codes\n",
    "\n",
    "y=df['Airport(Inchoen)']\n",
    "X=df[['intercept', 'Airline(Korean)','FlyingCompanion','AccessTime<=40','DepartureHr<=15',\n",
    "      'TripDuration<=7','GroupTravelYes','TripPurpose-Leisure', \n",
    "      'PR-Seoul,Others','Afternoon', 'Evening', 'Night','Airfare',\n",
    "      'FFD-SouthEast Asia', 'FFD-China,Others', 'FFD-Japan','FFD-North & South America',\n",
    "      'Destination-SouthEast Asia', 'Destination-China',\n",
    "      'OCC-Group2','OCC-Group1',  'Income-Group1','Income-Group2']]\n",
    "\n",
    "#Removed Male, Economy \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=109)\n",
    "\n",
    "#Female, Surrounding Area, Mode_of_transport_Category2, Night reference category\n",
    "logit_model1 = sm.Logit(y_train, X_train).fit()\n",
    "print(logit_model1.summary())\n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_train_pred = logit_model1.predict(X_train)\n",
    "y_train_pred_binary = (y_train_pred > 0.5).astype(int) \n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred_binary, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred_binary)\n",
    "precision_train = precision_score(y_train, y_train_pred_binary)\n",
    "recall_train = recall_score(y_train, y_train_pred_binary)\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "y_pred = logit_model1.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Converting probabilities to binary predictions\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred_binary,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n",
    "\n",
    "\n",
    "\n",
    "print(\"AIC:\", logit_model1.aic)\n",
    "print(\"BIC:\", logit_model1.bic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION MODEL (AIRLINE) \n",
    "\n",
    "df['Airline(Korean)'] = df['Airline'].map({1: 1, 2: 0, 3: 1, 4: 0})\n",
    "\n",
    "#Creating dummy variables for Airport\n",
    "df['Airport(Incheon)'] = np.where(df['Airport']==1, 1, 0)\n",
    "df['Airport(Gimpo)'] = np.where(df['Airport']==2, 1, 0) #reference\n",
    "\n",
    "\n",
    "#Creating dummy variables for TripDuration\n",
    "df['TripDuration<=5'] = np.where(df['TripDuration'] <= 5, 1, 0)\n",
    "df['TripDuration>5'] = np.where(df['TripDuration'] > 5, 1, 0)  #reference\n",
    "\n",
    "#Creating dummy variables for DepartureHr\n",
    "df['DepartureHr1'] = np.where(df['DepartureHr'] <= 15, 1, 0)\n",
    "df['DepartureHr2'] = np.where(df['DepartureHr'] > 15, 1, 0)  #reference\n",
    "\n",
    "\n",
    "# Creating dummy variables for FrequentFlightDestination\n",
    "df['FrequentDestination(SEAsia)'] = np.where(df['FrequentFlightDestination'].isin([1]), 1, 0) #SE Asia\n",
    "df['FrequentDestination(Japan)'] = np.where(df['FrequentFlightDestination'].isin([3,7]), 1, 0) #Japan, None\n",
    "df['FrequentDestination(Others)'] = np.where(df['FrequentFlightDestination'].isin([2,4,5,6]), 1, 0) #China, NA/SA, Europe, other - reference\n",
    "\n",
    "\n",
    "\n",
    "#Creating dummy variables for Destination\n",
    "df['Destination(China)'] = np.where(df['Destination'] .isin([1]), 1, 0) #China\n",
    "df['Destination(Japan)'] = np.where(df['Destination'].isin([2]), 1, 0) #Japan\n",
    "df['Destination(SEAsia)'] = np.where(df['Destination'].isin([3]), 1, 0) #SE Asia - reference\n",
    "\n",
    "\n",
    "\n",
    "#Creating dummy variables for SeatClass\n",
    "df['SeatClass(Economy)'] = np.where(df['SeatClass'].isin([1]), 1, 0) #Economy\n",
    "df['SeatClass(Business,First)'] = np.where(df['SeatClass'].isin([2,3]), 1, 0) #Business, First Class - reference\n",
    "\n",
    "\n",
    "#Creating dummy variables for Occupation\n",
    "df['Occupation(Business)'] = np.where(df['Occupation'].isin([2]), 1, 0) #Business\n",
    "df['Occupation(Others)'] = np.where(df['Occupation'].isin([3,8,12,1,9,10,11,4,5,6,7]), 1, 0)  #Other - reference\n",
    " \n",
    "\n",
    "\n",
    "#Creating dummy variables for Income\n",
    "df['IncomeGroup(30-80)'] = np.where(df['Income'].isin([2,3]), 1, 0) #30-80 Million Won\n",
    "df['Income-Group(<30&>80)'] = np.where(df['Income'].isin([1,4,5,6,7]), 1, 0) #<30&>80 Million Won - reference\n",
    "\n",
    "\n",
    "\n",
    "# LOGISTIC REGRESSION MODEL (AIRLINE)\n",
    "\n",
    "\n",
    "y=df['Airline(Korean)']\n",
    "X=df[['intercept', 'Airport(Incheon)',  'Airfare','TripDuration<=5','AccessTime<=40','FlyingCompanion','DepartureHr1',\n",
    "      'Night', 'Afternoon', 'Evening',  'FrequentDestination(SEAsia)','FrequentDestination(Japan)',\n",
    "       'Destination(China)','Destination(Japan)','SeatClass(Economy)', 'Occupation(Business)','IncomeGroup(30-80)']]\n",
    "         \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=109)\n",
    "\n",
    "logit_model2 = sm.Logit(y_train, X_train).fit()\n",
    "print(logit_model2.summary())\n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_train_pred = logit_model2.predict(X_train)\n",
    "y_train_pred_binary = (y_train_pred > 0.5).astype(int) \n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred_binary, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred_binary)\n",
    "precision_train = precision_score(y_train, y_train_pred_binary)\n",
    "recall_train = recall_score(y_train, y_train_pred_binary)\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "y_pred = logit_model2.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Converting probabilities to binary predictions\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred_binary,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n",
    "\n",
    "\n",
    "print(\"AIC:\", logit_model2.aic)\n",
    "print(\"BIC:\", logit_model2.bic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47cd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE MODEL (AIRPORT)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.tree import export_text\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "\n",
    "df['Gender_code'] = df['Gender'].astype('category').cat.codes\n",
    "df['Income_code'] = df['Income'].astype('category').cat.codes\n",
    "df['Airline_code'] = df['Airline'].astype('category').cat.codes\n",
    "df['Nationality_code'] = df['Nationality'].astype('category').cat.codes\n",
    "df['TripPurpose_code'] = df['TripPurpose'].astype('category').cat.codes\n",
    "df['ProvinceResidence_code'] = df['ProvinceResidence'].astype('category').cat.codes\n",
    "df['GroupTravel_code'] = df['GroupTravel'].astype('category').cat.codes\n",
    "df['Destination_code'] = df['Destination'].astype('category').cat.codes\n",
    "df['DepartureTime_code'] = df['DepartureTime'].astype('category').cat.codes\n",
    "df['SeatClass_code'] = df['SeatClass'].astype('category').cat.codes\n",
    "df['FrequentFlightDestination_code'] = df['FrequentFlightDestination'].astype('category').cat.codes\n",
    "df['NoTransport_code'] = df['NoTransport'].astype('category').cat.codes\n",
    "df['ModeTransport_code'] = df['ModeTransport'].astype('category').cat.codes\n",
    "df['Occupation_code'] = df['Occupation'].astype('category').cat.codes\n",
    "df['Airport_code'] = df['Airport'].astype('category').cat.codes\n",
    "X = df[['Gender_code','Airline_code','Nationality_code', 'TripPurpose_code', 'ProvinceResidence_code', 'GroupTravel_code','FrequentFlightDestination_code', 'Destination_code','DepartureTime_code','SeatClass_code','Age','TripDuration', 'FlyingCompanion', 'NoTripsLastYear', 'DepartureHr', 'Airfare', 'AccessTime','NoTransport_code','ModeTransport_code','Occupation_code','Income_code']] # Independent variables\n",
    "y = df['Airport_code']  # Dependent variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Export tree file\n",
    "dot_data = tree.export_graphviz(clf, out_file='Dtreeport.dot',\n",
    "feature_names=X.columns)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE MODEL (AIRLINE)\n",
    "\n",
    "df['Airline_code'] = df['Airline_Category'].astype('category').cat.codes\n",
    "\n",
    "X = df[['Gender_code','Airport_code','Nationality_code', 'TripPurpose_code', 'ProvinceResidence_code', 'TripDuration', 'FlyingCompanion', 'NoTripsLastYear', 'DepartureHr', 'Airfare', 'AccessTime','GroupTravel_code','FrequentFlightDestination_code', 'Destination_code','DepartureTime_code','SeatClass_code','NoTransport_code','ModeTransport_code','Occupation_code','Income_code']] # Independent variables\n",
    "y = df['Airline_code']  # Dependent variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Export tree file\n",
    "dot_data = tree.export_graphviz(clf, out_file='Dtreeline.dot',\n",
    "feature_names=X.columns)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred, average='macro')\n",
    "#precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred,average='macro')\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred,average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe89b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM MODEL (AIRPORT)\n",
    "\n",
    "X = df[['Age','FlyingCompanion','AccessTime','Gender_code','Airline_code','Nationality_code', 'TripPurpose_code', 'ProvinceResidence_code', 'GroupTravel_code'\n",
    "        ,'FrequentFlightDestination_code', 'Destination_code','DepartureTime_code','SeatClass_code','NoTransport_code'\n",
    "        ,'ModeTransport_code','Occupation_code','Income_code']]\n",
    "y = df['Airport_code']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svclassifier = SVC(kernel='poly',degree = 3) \n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = svclassifier.predict(X_train)\n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred,average='macro')# or 'micro', 'weighted' \n",
    "recall_train = recall_score(y_train, y_train_pred,average='macro') # or 'micro', 'weighted' \n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred,average='macro')\n",
    "recall = recall_score(y_test, y_pred,average='macro')\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM MODEL (AIRLINE)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "X = df[['Age','FlyingCompanion','AccessTime','Gender_code','Airport_code','Nationality_code', 'TripPurpose_code', 'ProvinceResidence_code'\n",
    "        , 'GroupTravel_code','FrequentFlightDestination_code', 'Destination_code','DepartureTime_code','SeatClass_code'\n",
    "        ,'NoTransport_code','ModeTransport_code','Occupation_code','Income_code']] # Independent variables\n",
    "y = df['Airline_code']  # Dependent variable\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svclassifier = SVC(kernel='poly', degree = 3) \n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = svclassifier.predict(X_train)\n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred,average='macro')\n",
    "recall_train = recall_score(y_train, y_train_pred,average='macro') \n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred,average='macro')\n",
    "recall = recall_score(y_test, y_pred,average='macro')\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK MODEL (AIRPORT)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = df[['Age','FlyingCompanion','AccessTime','Gender_code','Airline_code','Nationality_code', 'TripPurpose_code', 'ProvinceResidence_code', 'GroupTravel_code'\n",
    "        ,'FrequentFlightDestination_code', 'Destination_code','DepartureTime_code','SeatClass_code','NoTransport_code'\n",
    "        ,'ModeTransport_code','Occupation_code','Income_code']]\n",
    "y = df['Airport_code']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=55)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "## Multi-layer perceptron classification - one hidden layer of 3 neurons\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4), max_iter=1150)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predictions\n",
    "\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred) \n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK MODEL (AIRLINE)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = df[['Age','FlyingCompanion','AccessTime','Gender_code','Airport_code','Nationality_code', 'TripPurpose_code', 'ProvinceResidence_code'\n",
    "        , 'GroupTravel_code','FrequentFlightDestination_code', 'Destination_code','DepartureTime_code','SeatClass_code'\n",
    "        ,'NoTransport_code','ModeTransport_code','Occupation_code','Income_code']] # Independent variables\n",
    "y = df['Airline_code']  # Dependent variable\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "## Multi-layer perceptron classification - one hidden layer of 3 neurons\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4), max_iter=1090)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "train_conf_matrix = pd.crosstab(y_train, y_train_pred, rownames=['actual'],\n",
    "colnames=['predicted'])\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred) \n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Train precision:\", precision_train)\n",
    "print(\"Train Recall:\", recall_train)\n",
    "\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "testing_conf_matrix = pd.crosstab(y_test,y_pred,rownames\n",
    "=['actual'],colnames=['predicted'])\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(testing_conf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test precision:\", precision)\n",
    "print(\"Test Recall:\", recall) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b883c5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
